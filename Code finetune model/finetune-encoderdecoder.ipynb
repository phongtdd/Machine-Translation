{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T21:37:36.705166Z",
     "iopub.status.busy": "2024-12-13T21:37:36.704806Z",
     "iopub.status.idle": "2024-12-13T21:37:46.687121Z",
     "shell.execute_reply": "2024-12-13T21:37:46.686037Z",
     "shell.execute_reply.started": "2024-12-13T21:37:36.705127Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets evaluate accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T21:37:46.689340Z",
     "iopub.status.busy": "2024-12-13T21:37:46.689084Z",
     "iopub.status.idle": "2024-12-13T21:37:56.992711Z",
     "shell.execute_reply": "2024-12-13T21:37:56.991637Z",
     "shell.execute_reply.started": "2024-12-13T21:37:46.689317Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T21:37:56.994621Z",
     "iopub.status.busy": "2024-12-13T21:37:56.994246Z",
     "iopub.status.idle": "2024-12-13T21:38:05.324426Z",
     "shell.execute_reply": "2024-12-13T21:38:05.323333Z",
     "shell.execute_reply.started": "2024-12-13T21:37:56.994584Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T21:52:18.800650Z",
     "iopub.status.busy": "2024-12-13T21:52:18.799859Z",
     "iopub.status.idle": "2024-12-13T21:52:18.806117Z",
     "shell.execute_reply": "2024-12-13T21:52:18.805134Z",
     "shell.execute_reply.started": "2024-12-13T21:52:18.800606Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_data(root, folder):\n",
    "    data = {'en':[], 'vi':[]}\n",
    "    path = os.path.join(root, folder)\n",
    "    for file_name in os.listdir(path):\n",
    "        file_path = os.path.join(path, file_name)\n",
    "        with open(file_path,'r') as f:\n",
    "            _, tail = file_path.split('.')\n",
    "            if tail =='en':\n",
    "                for line in f:\n",
    "                    data['en'].append(line.strip())\n",
    "            else:\n",
    "                for line in f:\n",
    "                    data['vi'].append(line.strip())\n",
    "                    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T21:52:20.882828Z",
     "iopub.status.busy": "2024-12-13T21:52:20.882471Z",
     "iopub.status.idle": "2024-12-13T21:52:22.040865Z",
     "shell.execute_reply": "2024-12-13T21:52:22.040141Z",
     "shell.execute_reply.started": "2024-12-13T21:52:20.882797Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "root = \"/kaggle/input/\"\n",
    "\n",
    "train_data = read_data(root, 'trainnew')\n",
    "test_data = read_data(root, 'testnew')\n",
    "valid_data = read_data(root, 'validd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T21:52:24.520743Z",
     "iopub.status.busy": "2024-12-13T21:52:24.520362Z",
     "iopub.status.idle": "2024-12-13T21:52:26.578069Z",
     "shell.execute_reply": "2024-12-13T21:52:26.577097Z",
     "shell.execute_reply.started": "2024-12-13T21:52:24.520709Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "test_dataset = Dataset.from_dict(test_data)\n",
    "valid_dataset = Dataset.from_dict(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T21:52:29.761311Z",
     "iopub.status.busy": "2024-12-13T21:52:29.760443Z",
     "iopub.status.idle": "2024-12-13T21:52:29.765317Z",
     "shell.execute_reply": "2024-12-13T21:52:29.764196Z",
     "shell.execute_reply.started": "2024-12-13T21:52:29.761275Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset,\n",
    "    \"valid\": valid_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T21:52:31.271383Z",
     "iopub.status.busy": "2024-12-13T21:52:31.271052Z",
     "iopub.status.idle": "2024-12-13T21:52:31.277754Z",
     "shell.execute_reply": "2024-12-13T21:52:31.276745Z",
     "shell.execute_reply.started": "2024-12-13T21:52:31.271352Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T21:38:08.314522Z",
     "iopub.status.busy": "2024-12-13T21:38:08.313836Z",
     "iopub.status.idle": "2024-12-13T21:38:26.919354Z",
     "shell.execute_reply": "2024-12-13T21:38:26.918368Z",
     "shell.execute_reply.started": "2024-12-13T21:38:08.314485Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, EncoderDecoderModel, AutoModel\n",
    "\n",
    "# Define encoder and decoder model names\n",
    "encoder_model_name = \"bert-base-uncased\"  \n",
    "decoder_model_name = \"vinai/bartpho-word\"  \n",
    "\n",
    "# Load tokenizers\n",
    "encoder_tokenizer = AutoTokenizer.from_pretrained(encoder_model_name)\n",
    "decoder_tokenizer = AutoTokenizer.from_pretrained(decoder_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T21:38:26.923619Z",
     "iopub.status.busy": "2024-12-13T21:38:26.923090Z",
     "iopub.status.idle": "2024-12-13T21:38:26.930817Z",
     "shell.execute_reply": "2024-12-13T21:38:26.929868Z",
     "shell.execute_reply.started": "2024-12-13T21:38:26.923589Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "encoder_max_length=64\n",
    "decoder_max_length=64\n",
    "\n",
    "def process_data_to_model_inputs(batch):\n",
    "    inputs = encoder_tokenizer(batch[\"en\"], padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n",
    "    outputs = decoder_tokenizer(batch[\"vi\"], padding=\"max_length\", truncation=True, max_length=decoder_max_length)\n",
    "\n",
    "    batch[\"input_ids\"] = inputs.input_ids\n",
    "    batch[\"attention_mask\"] = inputs.attention_mask\n",
    "    batch[\"labels\"] = [\n",
    "        [-100 if token == decoder_tokenizer.pad_token_id else token for token in labels]\n",
    "        for labels in outputs.input_ids\n",
    "    ]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T21:38:26.932073Z",
     "iopub.status.busy": "2024-12-13T21:38:26.931820Z",
     "iopub.status.idle": "2024-12-13T21:39:34.846271Z",
     "shell.execute_reply": "2024-12-13T21:39:34.845427Z",
     "shell.execute_reply.started": "2024-12-13T21:38:26.932049Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "\n",
    "tokenizer_dataset = dataset.map(\n",
    "    process_data_to_model_inputs, \n",
    "    batched=True, \n",
    "    batch_size=batch_size,\n",
    "    remove_columns=[\"en\", \"vi\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T21:39:34.847901Z",
     "iopub.status.busy": "2024-12-13T21:39:34.847537Z",
     "iopub.status.idle": "2024-12-13T21:39:34.854452Z",
     "shell.execute_reply": "2024-12-13T21:39:34.853536Z",
     "shell.execute_reply.started": "2024-12-13T21:39:34.847861Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T21:39:34.855800Z",
     "iopub.status.busy": "2024-12-13T21:39:34.855519Z",
     "iopub.status.idle": "2024-12-13T21:39:36.350315Z",
     "shell.execute_reply": "2024-12-13T21:39:36.349576Z",
     "shell.execute_reply.started": "2024-12-13T21:39:34.855772Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T21:39:36.351864Z",
     "iopub.status.busy": "2024-12-13T21:39:36.351331Z",
     "iopub.status.idle": "2024-12-13T21:39:36.357648Z",
     "shell.execute_reply": "2024-12-13T21:39:36.356794Z",
     "shell.execute_reply.started": "2024-12-13T21:39:36.351836Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # Decode predictions and labels\n",
    "    pred_str = decoder_tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = decoder_tokenizer.pad_token_id\n",
    "    label_str = decoder_tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])\n",
    "    rouge2_score = rouge_output[\"rouge2\"]\n",
    "\n",
    "    return {\n",
    "        \"rouge2_precision\": round(rouge2_score, 4),\n",
    "        \"rouge2_recall\": round(rouge2_score, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge2_score, 4),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T21:39:36.359105Z",
     "iopub.status.busy": "2024-12-13T21:39:36.358766Z",
     "iopub.status.idle": "2024-12-13T21:39:47.379747Z",
     "shell.execute_reply": "2024-12-13T21:39:47.379019Z",
     "shell.execute_reply.started": "2024-12-13T21:39:36.359064Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Combine into an EncoderDecoderModel\n",
    "model = EncoderDecoderModel.from_encoder_decoder_pretrained(\n",
    "    encoder_model_name,\n",
    "    decoder_model_name\n",
    ")\n",
    "\n",
    "model.config.decoder_start_token_id = decoder_tokenizer.cls_token_id\n",
    "model.config.pad_token_id = decoder_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T21:39:47.381107Z",
     "iopub.status.busy": "2024-12-13T21:39:47.380825Z",
     "iopub.status.idle": "2024-12-13T21:39:47.385176Z",
     "shell.execute_reply": "2024-12-13T21:39:47.384265Z",
     "shell.execute_reply.started": "2024-12-13T21:39:47.381081Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load your parallel dataset\n",
    "train_dataset = tokenizer_dataset['train']\n",
    "val_dataset = tokenizer_dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, EarlyStoppingCallback\n",
    "\n",
    "# Define training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",  \n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs = 5, \n",
    "    save_total_limit=2,\n",
    "    predict_with_generate=True,\n",
    "    report_to=\"none\",\n",
    "    metric_for_best_model=\"eval_loss\",  \n",
    "    greater_is_better=False,  \n",
    "    load_best_model_at_end=True,  \n",
    "    save_strategy=\"epoch\"  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=2  # Stop training if no improvement for 2 consecutive evaluations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T21:39:53.680443Z",
     "iopub.status.busy": "2024-12-13T21:39:53.680136Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize the trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stopping_callback] \n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./translation_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inputs = encoder_tokenizer(\n",
    "    \"On Sunday, September 1, 2019, Hurricane Dorian, one of the strongest hurricanes ever recorded in the Atlantic Ocean, with winds of 362 km/h, made landfall on Great Abaco Island, northern Bahamas.\", \n",
    "    return_tensors=\"pt\", \n",
    "    padding=True, \n",
    "    truncation=True, \n",
    "    max_length=64\n",
    ")\n",
    "\n",
    "# Move inputs to the model's device\n",
    "inputs = {key: value.to(model.device) for key, value in inputs.items()}\n",
    "\n",
    "# Generate outputs\n",
    "outputs = model.generate(inputs[\"input_ids\"], max_length=64, num_beams=4)\n",
    "\n",
    "# Decode the output\n",
    "print(decoder_tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "# Function to evaluate model predictions on the test set\n",
    "def evaluate_model(model, encoder_tokenizer, decoder_tokenizer, test_data):\n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    for item in test_data:\n",
    "        source = item[\"en\"]\n",
    "        target = item[\"vi\"]\n",
    "        \n",
    "        # Tokenize the source sentence\n",
    "        inputs = encoder_tokenizer(source, \n",
    "                                    padding=True, \n",
    "                                    truncation=True, \n",
    "                                    max_length=64,\n",
    "                                    return_tensors=\"pt\")\n",
    "        inputs = {key: value.to(model.device) for key, value in inputs.items()}\n",
    "        # Generate translation\n",
    "        outputs = model.generate(inputs[\"input_ids\"], max_length=64, num_beams=4)\n",
    "        prediction = decoder_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        predictions.append(prediction)\n",
    "        references.append(target)\n",
    "        \n",
    "    \n",
    "    return predictions, references\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "small_test_dataset =dataset[\"test\"].shuffle(seed=42).select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "smoothing = SmoothingFunction().method1\n",
    "\n",
    "# Calculate BLEU score with smoothing\n",
    "def calculate_bleu(predictions, references):\n",
    "    scores = []\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        ref_tokens = ref.split()\n",
    "        pred_tokens = pred.split()\n",
    "        score = sentence_bleu([ref_tokens], pred_tokens, smoothing_function=smoothing)\n",
    "        scores.append(score)\n",
    "    return sum(scores) / len(scores) \n",
    "\n",
    "bleu_score = calculate_bleu(predictions, references)\n",
    "print(f\"BLEU Score with Smoothing: {bleu_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6289982,
     "sourceId": 10182300,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6290812,
     "sourceId": 10183431,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6290824,
     "sourceId": 10183444,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6298669,
     "sourceId": 10193937,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
