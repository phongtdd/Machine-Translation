{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:42:39.556970Z",
     "iopub.status.busy": "2024-12-12T22:42:39.556606Z",
     "iopub.status.idle": "2024-12-12T22:42:50.977148Z",
     "shell.execute_reply": "2024-12-12T22:42:50.976209Z",
     "shell.execute_reply.started": "2024-12-12T22:42:39.556936Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets evaluate accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:42:50.980819Z",
     "iopub.status.busy": "2024-12-12T22:42:50.979894Z",
     "iopub.status.idle": "2024-12-12T22:42:52.333228Z",
     "shell.execute_reply": "2024-12-12T22:42:52.332459Z",
     "shell.execute_reply.started": "2024-12-12T22:42:50.980773Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "root = '/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:42:52.335050Z",
     "iopub.status.busy": "2024-12-12T22:42:52.334453Z",
     "iopub.status.idle": "2024-12-12T22:42:52.339603Z",
     "shell.execute_reply": "2024-12-12T22:42:52.338560Z",
     "shell.execute_reply.started": "2024-12-12T22:42:52.334986Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:42:52.341098Z",
     "iopub.status.busy": "2024-12-12T22:42:52.340758Z",
     "iopub.status.idle": "2024-12-12T22:42:52.357412Z",
     "shell.execute_reply": "2024-12-12T22:42:52.356498Z",
     "shell.execute_reply.started": "2024-12-12T22:42:52.341063Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_files = {}\n",
    "for file in os.listdir(root):\n",
    "    file_path = root+file\n",
    "    name = file.split('.')[0]\n",
    "    data_files[name] = os.path.join(root, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:42:52.359756Z",
     "iopub.status.busy": "2024-12-12T22:42:52.359471Z",
     "iopub.status.idle": "2024-12-12T22:42:52.366263Z",
     "shell.execute_reply": "2024-12-12T22:42:52.365356Z",
     "shell.execute_reply.started": "2024-12-12T22:42:52.359728Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:42:52.367944Z",
     "iopub.status.busy": "2024-12-12T22:42:52.367570Z",
     "iopub.status.idle": "2024-12-12T22:43:26.878656Z",
     "shell.execute_reply": "2024-12-12T22:43:26.877580Z",
     "shell.execute_reply.started": "2024-12-12T22:42:52.367904Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "datasets = load_dataset(\"csv\", data_files = data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:43:26.880651Z",
     "iopub.status.busy": "2024-12-12T22:43:26.880019Z",
     "iopub.status.idle": "2024-12-12T22:43:26.960818Z",
     "shell.execute_reply": "2024-12-12T22:43:26.960011Z",
     "shell.execute_reply.started": "2024-12-12T22:43:26.880605Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "datasets['train'] = datasets['train'].shuffle(seed=42).select(range(30000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:43:26.962270Z",
     "iopub.status.busy": "2024-12-12T22:43:26.961950Z",
     "iopub.status.idle": "2024-12-12T22:43:27.883607Z",
     "shell.execute_reply": "2024-12-12T22:43:27.882574Z",
     "shell.execute_reply.started": "2024-12-12T22:43:26.962241Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:43:27.885203Z",
     "iopub.status.busy": "2024-12-12T22:43:27.884856Z",
     "iopub.status.idle": "2024-12-12T22:43:32.956837Z",
     "shell.execute_reply": "2024-12-12T22:43:32.955789Z",
     "shell.execute_reply.started": "2024-12-12T22:43:27.885172Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:43:32.958605Z",
     "iopub.status.busy": "2024-12-12T22:43:32.958126Z",
     "iopub.status.idle": "2024-12-12T22:43:32.964421Z",
     "shell.execute_reply": "2024-12-12T22:43:32.963315Z",
     "shell.execute_reply.started": "2024-12-12T22:43:32.958574Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"article\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"highlights\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:43:32.965873Z",
     "iopub.status.busy": "2024-12-12T22:43:32.965494Z",
     "iopub.status.idle": "2024-12-12T22:45:16.108174Z",
     "shell.execute_reply": "2024-12-12T22:45:16.107121Z",
     "shell.execute_reply.started": "2024-12-12T22:43:32.965826Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "\n",
    "tokenizer_datasets = datasets.map(preprocess_function, batched = True, batch_size=batch_size, remove_columns=['id', 'article', 'highlights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:45:16.109607Z",
     "iopub.status.busy": "2024-12-12T22:45:16.109314Z",
     "iopub.status.idle": "2024-12-12T22:45:16.116314Z",
     "shell.execute_reply": "2024-12-12T22:45:16.115109Z",
     "shell.execute_reply.started": "2024-12-12T22:45:16.109579Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:45:16.118116Z",
     "iopub.status.busy": "2024-12-12T22:45:16.117715Z",
     "iopub.status.idle": "2024-12-12T22:45:33.760878Z",
     "shell.execute_reply": "2024-12-12T22:45:33.759883Z",
     "shell.execute_reply.started": "2024-12-12T22:45:16.118074Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:45:33.768430Z",
     "iopub.status.busy": "2024-12-12T22:45:33.767218Z",
     "iopub.status.idle": "2024-12-12T22:45:33.773501Z",
     "shell.execute_reply": "2024-12-12T22:45:33.772461Z",
     "shell.execute_reply.started": "2024-12-12T22:45:33.768381Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:45:33.775011Z",
     "iopub.status.busy": "2024-12-12T22:45:33.774728Z",
     "iopub.status.idle": "2024-12-12T22:45:33.935340Z",
     "shell.execute_reply": "2024-12-12T22:45:33.934273Z",
     "shell.execute_reply.started": "2024-12-12T22:45:33.774983Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    num_train_epochs=15,\n",
    "    fp16=True,\n",
    "    report_to = 'none'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T22:45:33.936792Z",
     "iopub.status.busy": "2024-12-12T22:45:33.936509Z",
     "iopub.status.idle": "2024-12-12T23:16:41.325442Z",
     "shell.execute_reply": "2024-12-12T23:16:41.324474Z",
     "shell.execute_reply.started": "2024-12-12T22:45:33.936764Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenizer_datasets[\"train\"],\n",
    "    eval_dataset=tokenizer_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T23:19:43.556382Z",
     "iopub.status.busy": "2024-12-12T23:19:43.555668Z",
     "iopub.status.idle": "2024-12-12T23:19:44.166893Z",
     "shell.execute_reply": "2024-12-12T23:19:44.165901Z",
     "shell.execute_reply.started": "2024-12-12T23:19:43.556345Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save_pretrained('pretrained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T10:11:18.057496Z",
     "iopub.status.busy": "2024-12-13T10:11:18.057121Z",
     "iopub.status.idle": "2024-12-13T10:11:21.779202Z",
     "shell.execute_reply": "2024-12-13T10:11:21.778321Z",
     "shell.execute_reply.started": "2024-12-13T10:11:18.057465Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Transformers library provides thousands of pretrained models to perform tasks on texts such as classification, information extraction, question answering, summarization, translation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('/kaggle/input/21312/keras/default/1/results/checkpoint-28125')\n",
    "\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('/kaggle/input/21312/keras/default/1/results/checkpoint-28125')\n",
    "\n",
    "\n",
    "input_text = (\n",
    "    \"summarize: The Transformers library provides thousands of pretrained models to perform tasks on texts such as classification, \"\n",
    "    \"information extraction, question answering, summarization, translation, text generation, and more. It is maintained by Hugging Face.\"\n",
    ")\n",
    "\n",
    "# Tokenize input\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=512).input_ids\n",
    "\n",
    "# Generate summary\n",
    "outputs = model.generate(input_ids, max_length=100, min_length=20, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "# Decode and print summary\n",
    "summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"Summary:\", summary)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1654566,
     "sourceId": 2734496,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 190399,
     "modelInstanceId": 168061,
     "sourceId": 197071,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
